{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataSciBurgoon/2024_ASCCT_CE/blob/main/ASCCT_SimIntro_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "id": "d69555d9",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "d69555d9"
      },
      "source": [
        "# Proof by Simulations\n",
        "\n",
        "- Instructor: Claudio Fuentes\n",
        "- Affiliation: Oregon State University, Department of Statistics\n",
        "- Presentation for:\n",
        "  - ASCCT 13th Annual Meeting\n",
        "  - RTI International Campus\n",
        "  - Research Triangle Park, North Carolina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d53224",
      "metadata": {
        "id": "25d53224"
      },
      "outputs": [],
      "source": [
        "# # Install packages, as needed.\n",
        "# # Only need to do this once in your Google Colab session.\n",
        "# install.packages(\"lattice\")\n",
        "# install.packages(\"mvtnorm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbbf8dd8",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "dbbf8dd8"
      },
      "outputs": [],
      "source": [
        "# Load packages once installed\n",
        "library(lattice)\n",
        "library(mvtnorm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd3b0ff",
      "metadata": {
        "id": "abd3b0ff"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "One of the advantages of having computing power and statistical softwares is that we can run simulation experiments to evaluate performance of our models, the robustness and limitations of different procedures, or simply to further understand some concepts.\n",
        "\n",
        "Here, we will consider a few simple examples and will set up simulations experiments to illustrate and explore some relevant concepts.\n",
        "\n",
        "First, we need learn an important tool that is very useful when conducting simulation exercises so we can replicate and share our results.\n",
        "\n",
        "Say that we want to generate 5 observations from a Normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb593b31",
      "metadata": {
        "echo": true,
        "id": "eb593b31"
      },
      "outputs": [],
      "source": [
        "# This function is generating 5 random observations from a Normal distribution\n",
        "# with mean 0 and standard deviation 1\n",
        "rnorm(n = 5, mean = 0, sd = 1)\n",
        "\n",
        "# Here we are generating 5 new random observations from a Normal distribution\n",
        "# with mean 0 and standard deviation 1\n",
        "rnorm(5, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9072fec",
      "metadata": {
        "id": "e9072fec"
      },
      "source": [
        "Note that when we run the code for the second time, we get a different set of 5 observations from a Normal distribution.\n",
        "\n",
        "This is usually ok, because we want to generate 5 random observations. However, if you would like to share your code or reproduce your own results, you won't be able to do so because every time we run that line we will get 5 (probably) different random observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855d3904",
      "metadata": {
        "id": "855d3904"
      },
      "outputs": [],
      "source": [
        "rnorm(5, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b78510",
      "metadata": {
        "id": "77b78510"
      },
      "source": [
        "There is a way to \"fix\" this problem, using the `set.seed(.)` function in R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27303dc3",
      "metadata": {
        "echo": true,
        "id": "27303dc3"
      },
      "outputs": [],
      "source": [
        "# In the function we are using \"512\" as the seed, but we can pick any other\n",
        "# integer\n",
        "set.seed(512)\n",
        "rnorm(5, 0, 1)\n",
        "\n",
        "set.seed(512)\n",
        "rnorm(5, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272ee48a",
      "metadata": {
        "id": "272ee48a"
      },
      "source": [
        "We note now that we have generated two identical sets of 5 observations from a normal distribution.\n",
        "\n",
        "If we run the `rnorm(.)` function again, we will get a different set. But if we set the seed 512 again, we will be able to reproduce the results above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23b5139",
      "metadata": {
        "id": "b23b5139"
      },
      "outputs": [],
      "source": [
        "# Generate 5 new random observations\n",
        "rnorm(5,0,1)\n",
        "\n",
        "# Now we get the same numbers we got before\n",
        "set.seed(512)\n",
        "rnorm(5, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b44ff10",
      "metadata": {
        "id": "1b44ff10"
      },
      "source": [
        "# 2. Sampling distributions and transformations\n",
        "\n",
        "Let's start by generating observations from two populations $X$ and $Y$ and plot a histogram of the observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79621181",
      "metadata": {
        "echo": true,
        "id": "79621181"
      },
      "outputs": [],
      "source": [
        "# Set a seed so everyone's \"random\" results will be the same.\n",
        "set.seed(159823)\n",
        "\n",
        "# Set the sizes of our two samples\n",
        "n1 <- 1000\n",
        "n2 <- 1000\n",
        "\n",
        "# Generate samples from our two populations\n",
        "X <- 100 * rgamma(n1, shape = 0.58, scale= 2 / 0.58)\n",
        "Y <- 100 * exp(rnorm(n2, log(2) - 1, sqrt(2)))\n",
        "\n",
        "# Plot the distributions of our samples\n",
        "par(mfrow=c(1,2))\n",
        "hist(X, breaks=seq(0, 6200, 100), main=\"Histogram for X\", xlab=\"x-values\")\n",
        "hist(Y, breaks=seq(0, 6200, 100), main=\"Histogram for Y\", xlab=\"y-values\")\n",
        "par(mfrow=c(1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6242ff1b",
      "metadata": {
        "id": "6242ff1b"
      },
      "source": [
        "Suppose that we are interested in performing a test to compare the means of these two populations. Can we just perform a t-test? Or should we consider a transformation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc04b20",
      "metadata": {
        "echo": true,
        "id": "adc04b20"
      },
      "outputs": [],
      "source": [
        "# t-test results on our original scale\n",
        "t.test(X, Y)\n",
        "\n",
        "# t-test after log transformation\n",
        "t.test(log(X), log(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff1a240",
      "metadata": {
        "id": "aff1a240"
      },
      "source": [
        "Even though the original populations are skewed, both tests are valid, but different. In the first test the null hypothesis is\n",
        "$$H_0: \\mu_x=\\mu_y,$$\n",
        "where $\\mu_x,\\mu_y$ are the population means of the populations for $X$ and $Y$ respectively.\n",
        "\n",
        "In the second test the null hypothesis is\n",
        "$$H_0: \\mu_{log(x)}=\\mu_{log(y)},$$\n",
        "where $\\mu_{log(x)},\\mu_{log(y)}$ are the population means of the log transformed variables $X$ and $Y$ respectively.\n",
        "\n",
        "# 3. Confidence intervals\n",
        "\n",
        "Let's recall from our stats courses how to construct a confidence interval for the population mean. Say that we observe draw $n$ observations from a $N(\\mu,1)$ distributed population, where $\\mu$ is unknown. That is, we don't know what the average value for some variable of interest is with a population, but we'd like to use a sample to gather some information about what the population mean might be.\n",
        "\n",
        "We can construct a $(1-\\alpha)\\times 100\\%$ confidence interval for $\\mu$, based on our observations using the formula\n",
        "$$\n",
        "\\bar{x} \\pm z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n",
        "$$\n",
        "Some people misinterpret a (say) 95% confidence interval as a 95% probability that the the true mean will land in the resulting interval. We will conduct a short simulation experiment to help us understand the concept of \"confidence level\".\n",
        "\n",
        "First, we set up our simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad815f9",
      "metadata": {
        "id": "aad815f9"
      },
      "outputs": [],
      "source": [
        "# Population mean (Considered \"unknown\" even though we know it's equal to 1)\n",
        "mu <- 1\n",
        "\n",
        "# Population standard deviation (known)\n",
        "sigma <- 1\n",
        "\n",
        "# Sample size in one run of the experiment (i.e. number of observations we\n",
        "# have)\n",
        "n.sample <- 10\n",
        "\n",
        "# Number of times we will repeat the experiment\n",
        "N.rep <- 1000\n",
        "\n",
        "# alpha for the desired (1-alpha)x100% Confidence level\n",
        "alpha <- 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566f7b59",
      "metadata": {
        "id": "566f7b59"
      },
      "source": [
        "In this set up `n.sample` is the number of observations we will draw from the $N(\\mu,1)$ distribution in one repetition of the experiment (this would correspond to the sample size we would have in a real experiment).\n",
        "\n",
        "On the other hand, `N.rep` corresponds to the number of times we want to repeat the entire experiment. That is, if we went to the lab over and over again, and each time we obtain 10 observations from our experiment (this is what we can't do in a real situation, but can simulate using a computer).\n",
        "\n",
        "Note that in a \"real\" experiment the true value of $\\mu$ would be unknown. But here we need to assign a value so we can run the simulations. Still, we will perform all the calculations pretending we don't know what the value of $\\mu$ is to check if we can get the expected results.\n",
        "\n",
        "Now, because the observations are drawn from a Normal distribution, we know that the sampling distribution of the sample mean is also Normal. More specifically, we know that\n",
        "\n",
        "$$\n",
        "\\bar{X}\\sim N\\big(\\mu,\\sigma^2/n\\big)\n",
        "$$\n",
        "\n",
        "So we can generate the `N.rep` repetitions of the experiment using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384d0f91",
      "metadata": {
        "id": "384d0f91"
      },
      "outputs": [],
      "source": [
        "# Sample means generated from sampling distribution\n",
        "x.bar <- rnorm(N.rep, mean = mu, sd = sigma / sqrt(n.sample))\n",
        "# Read the first few observations\n",
        "head(x.bar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f916f6da",
      "metadata": {
        "id": "f916f6da"
      },
      "source": [
        "Now we can construct the confidence intervals for each one of the replications of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5efb7f4",
      "metadata": {
        "id": "a5efb7f4"
      },
      "outputs": [],
      "source": [
        "# z-value for confidence intervals\n",
        "z <- qnorm(alpha / 2, mean = 0, sd = 1, lower.tail=FALSE)\n",
        "\n",
        "# Confidence interval lower bound\n",
        "low.bound <- (x.bar - z * sigma / sqrt(n.sample))\n",
        "\n",
        "# Confidence interval upper bound\n",
        "up.bound <- (x.bar + z * sigma / sqrt(n.sample))\n",
        "\n",
        "# Data frame to see the intervals in column-form\n",
        "CI <- data.frame(low.bound,up.bound)\n",
        "\n",
        "# Read the first few observations\n",
        "head(CI)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e92ce5",
      "metadata": {
        "id": "08e92ce5"
      },
      "source": [
        "Finally, we need to check how many of these intervals contain the true value of $\\mu$. Since we know that $\\mu=1$ (At least for our simulation scenario) we should obtain approximately $(1-\\alpha)\\times 100\\%$ of the intervals we constructed containing the true value of $\\mu$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f203727",
      "metadata": {
        "id": "9f203727"
      },
      "outputs": [],
      "source": [
        "# Check if resulting interval contains the true parameter\n",
        "contains <- (mu >= low.bound & mu <= up.bound)\n",
        "\n",
        "# Observed proportion of intervals that cover the true value of the parameter\n",
        "sum(contains) / N.rep"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe83c48",
      "metadata": {
        "id": "ffe83c48"
      },
      "source": [
        "# 4. Uncertainty in regression models\n",
        "\n",
        "Consider now a similar experiment in the context of linear regression. Fist we will generate observations from a true model and we will fit the linear regression line to the generated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a39ad2",
      "metadata": {
        "id": "46a39ad2"
      },
      "outputs": [],
      "source": [
        "# This is the explanatory variable, created using n = 12 random values # uniformly distributed between min = 15 and max = 25.\n",
        "X1 <- runif(n = 12, min = 15, max = 25)\n",
        "\n",
        "# This is the response variable following the true model with intercept 5 and slope 0.5.\n",
        "# The term \"rnorm(length(X1), mean = 0, sd = 2)\" is generating random errors\n",
        "Y <- 5 + 0.5 * X1 + rnorm(length(X1), mean = 0, sd = 2)\n",
        "\n",
        "# Here we are fitting the model to the generated data\n",
        "fit <- lm(Y ~ X1)\n",
        "\n",
        "# Are the estimated coefficients any close to the true values?\n",
        "summary(fit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "049f0364",
      "metadata": {
        "id": "049f0364"
      },
      "source": [
        "We can plot the observations, fitted line and true line, so we can visualize the situation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdeb578",
      "metadata": {
        "id": "dfdeb578"
      },
      "outputs": [],
      "source": [
        "plot(x = X1, y = Y,\n",
        "     type=\"p\", pch=20, col=\"blue\",\n",
        "     xlim=c(0, 25), ylim=c(0, 25),\n",
        "     xlab = \"X\",ylab = \"Y\", main=\"\")\n",
        "abline(fit, col = \"blue\", lwd = 1.5)\n",
        "abline(a = 5, b = 0.5, col = \"red\", lwd = 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f8bd45",
      "metadata": {
        "id": "e8f8bd45"
      },
      "source": [
        "Now, we can construct the confidence intervals for the mean response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b23a0f",
      "metadata": {
        "id": "a1b23a0f"
      },
      "outputs": [],
      "source": [
        "# We will construct intervals at each one of these points\n",
        "# so we can plot them later as a \"confidence band\" surrounding the fitted line\n",
        "newx1 <- seq(0, 25, by=0.05)\n",
        "conf_interval <- predict(fit,\n",
        "                         newdata=data.frame(X1 = newx1),\n",
        "                         interval=\"confidence\",\n",
        "                         level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "515e24b3",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "515e24b3"
      },
      "source": [
        "Let's add the confidence intervals to the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61ec66d7",
      "metadata": {
        "id": "61ec66d7"
      },
      "outputs": [],
      "source": [
        "plot(x = X1, y = Y,\n",
        "     type=\"p\", pch=20, col=\"blue\",\n",
        "     xlim=c(0, 25), ylim=c(0, 25),\n",
        "     xlab = \"X\",ylab = \"Y\", main=\"\")\n",
        "abline(fit, col = \"blue\", lwd = 1.5)\n",
        "abline(a = 5, b = 0.5, col = \"red\", lwd = 1.5)\n",
        "\n",
        "# This will plot the lower band\n",
        "lines(newx1, conf_interval[,2], col=\"blue\", lty=2)\n",
        "\n",
        "# This will plot the upper band\n",
        "lines(newx1, conf_interval[,3], col=\"blue\", lty=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67513218",
      "metadata": {
        "id": "67513218"
      },
      "source": [
        "Now we can obtain the prediction intervals for a \"future\" response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "602c99c2",
      "metadata": {
        "id": "602c99c2"
      },
      "outputs": [],
      "source": [
        "pred_interval <- predict(fit,\n",
        "                         newdata=data.frame(X1=newx1),\n",
        "                         interval=\"prediction\",\n",
        "                         level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f29e349",
      "metadata": {
        "id": "7f29e349"
      },
      "source": [
        "and add the prediction bands to the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2a36a28",
      "metadata": {
        "id": "f2a36a28"
      },
      "outputs": [],
      "source": [
        "plot(x = X1, y = Y,\n",
        "     type=\"p\", pch=20, col=\"blue\",\n",
        "     xlim=c(0, 25), ylim=c(0, 25),\n",
        "     xlab = \"X\",ylab = \"Y\", main=\"\")\n",
        "abline(fit, col = \"blue\", lwd = 1.5)\n",
        "abline(a = 5, b = 0.5, col = \"red\", lwd = 1.5)\n",
        "\n",
        "# Add the confidence interval\n",
        "lines(newx1, conf_interval[,2], col=\"blue\", lty=2)\n",
        "lines(newx1, conf_interval[,3], col=\"blue\", lty=2)\n",
        "\n",
        "# Add the prediction intervals\n",
        "lines(newx1, pred_interval[,2], col=\"darkgreen\", lty=2)\n",
        "lines(newx1, pred_interval[,3], col=\"darkgreen\", lty=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ff979a1",
      "metadata": {
        "id": "5ff979a1"
      },
      "source": [
        "We observe that the estimated value of the slope coefficient does not match with the true value of the slope (which is expected), but perhaps a confidence interval for $\\beta_1$ will capture the true value of the coefficient.\n",
        "\n",
        "We can run simulations to check the performance of such intervals and explore the connections with other concepts, such as P-values. First, we set up the simulation framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6b6ad7",
      "metadata": {
        "id": "0a6b6ad7"
      },
      "outputs": [],
      "source": [
        "# Set up the simulation parameters\n",
        "\n",
        "# Number of repeated \"experiments\"\n",
        "M <- 1000\n",
        "\n",
        "# Each experiment will be of sample size ...\n",
        "n.sample <- 12\n",
        "\n",
        "# Additional confidence interval parameters\n",
        "sigma <-  2\n",
        "alpha <- 0.05\n",
        "\n",
        "# Some empty vectors to \"store\" the results of our M experiments.\n",
        "pvalue <- vector(\"numeric\", M)\n",
        "beta1 <- vector (\"numeric\",M)\n",
        "coverage <- vector(\"logical\",M)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afdfce8c",
      "metadata": {
        "id": "afdfce8c"
      },
      "source": [
        "Once we set up the simulation parameters, we can generate observations, construct the intervals and look at P-values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6927a25",
      "metadata": {
        "id": "c6927a25"
      },
      "outputs": [],
      "source": [
        "# Using a for loop to allow us to repeat our fairly complex experiments\n",
        "for(i in 1:M) {\n",
        "\n",
        "  # Generate our explanatory and response values\n",
        "  X <- runif(n.sample,min = 15, max = 25)\n",
        "  Y <- 5 + 0.5 * X + rnorm(length(X), mean = 0, sd = sigma)\n",
        "\n",
        "  # Generate our \"critical value\" for the confidence intervals.\n",
        "  t <- qt(alpha / 2, n.sample - 1, lower.tail = FALSE)\n",
        "\n",
        "  # Fit the regression model\n",
        "  model <- lm(Y ~ X)\n",
        "\n",
        "  # Extract estimated coefficients, store them in our storage vector\n",
        "  beta1[i] <- summary(model)$coeff[2,1]\n",
        "\n",
        "  # Extract corresponding p-value, store it in our storage vector\n",
        "  pvalue[i] <- summary(model)$coeff[2,4]\n",
        "\n",
        "  # Check if reulting interval contains the true parameter\n",
        "  coverage[i] <- (0.5 >= summary(model)$coeff[2,1] -\n",
        "                    t*summary(model)$coeff[2,2] & 0.5 <=\n",
        "                    summary(model)$coeff[2,1] +\n",
        "                    t*summary(model)$coeff[2,2])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ace88c3",
      "metadata": {
        "id": "6ace88c3"
      },
      "source": [
        "When the simulations are done we can use them evaluate the performance of the procedures using different metrics and visualization tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d41474c",
      "metadata": {
        "id": "4d41474c"
      },
      "outputs": [],
      "source": [
        "# Construct histogram\n",
        "# What is the histogram of the estimated coefficients telling you?\n",
        "hist(beta1, breaks =  50)\n",
        "\n",
        "# Observed proportion of intervals that cover the true value of the parameter\n",
        "# What do you think of the observed coverage of the intervals?\n",
        "sum(coverage) / M\n",
        "\n",
        "# Check if P-value is not \"significant\" (Observed proportion of rejections)\n",
        "# What do you think of the proportion of times you fail to reject the\n",
        "# hypothesis\n",
        "# H_0 : beta_1 = 0?\n",
        "fail.reject <- (pvalue > alpha)\n",
        "sum(fail.reject) / M"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79f8dcd",
      "metadata": {
        "id": "e79f8dcd"
      },
      "source": [
        "# 5. Multicollinearity\n",
        "\n",
        "When evaluating a model of the form\n",
        "$$\n",
        "\\mu\\{Y|\\mathbf{X}\\}=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\ldots+\\beta_pX_p\n",
        "$$\n",
        "it is not uncommon to look at the P-values of the individual coefficients to determine which variables are \"important\" by assessing significance.\n",
        "\n",
        "However, the precision in estimating a particular regression coefficient may be affected when several explanatory variables are included in the model.\n",
        "\n",
        "This loss of precision is expressed in usually large values for the standard errors of the estimated coefficients due to strong correlations among the explanatory variables in the model.\n",
        "\n",
        "As a result, we might observe that some variables are not significant simply, because the the standard errors are too big.\n",
        "\n",
        "## 5.1 Example\n",
        "\n",
        "Let's run a short simulation example to understand multicollinearity:\n",
        "\n",
        "- Construct a set of 3 explanatory variables $X_1, X_2, X_3$, so that $X_1, X_2$ are correlated, but $X_1, X_3$ are independent.\n",
        "- Construct a response variable $Y$, so that $Y$ is associated with $X_1$, but not with $X_2, X_3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b2b62e",
      "metadata": {
        "id": "a4b2b62e"
      },
      "outputs": [],
      "source": [
        "# Construct our explanatory variables.\n",
        "X1 <- runif(n = 50, min = 0, max = 20)\n",
        "X2 <- 5 + 0.5 * X1 + rnorm(length(X1), mean = 0, sd = 0.025)\n",
        "X3 <- runif(n = 50, min = 0, max = 20)\n",
        "\n",
        "# Construct our response variable.\n",
        "Y <- 10 + 15 * X1 + rnorm(length(X1), mean = 0, sd = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed650b5f",
      "metadata": {
        "id": "ed650b5f"
      },
      "source": [
        "Looking at the correlations among the predictors we obtain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82cbba9",
      "metadata": {
        "id": "d82cbba9"
      },
      "outputs": [],
      "source": [
        "# Correlation between X1 and X2\n",
        "cor(X1,X2)\n",
        "\n",
        "# Correlation between X1 and X3\n",
        "cor(X1,X3)\n",
        "\n",
        "# Plot two plots, side by side\n",
        "par(mfrow=c(1,2))\n",
        "\n",
        "# High correlation variables scatterplot\n",
        "plot(x = X1, y = X2,\n",
        "     pch = 19, col = \"blue\",\n",
        "     main= \"High correlation\",\n",
        "     xlab=\"X2 vs X1\")\n",
        "\n",
        "# Low correlation variables scatterplot\n",
        "plot(x = X1, y = X3,\n",
        "     pch = 19, col = \"blue\",\n",
        "     main = \"Low correlation\",\n",
        "     xlab =\"X3 vs X1\")\n",
        "\n",
        "# Reset so plots show up on their own\n",
        "par(mfrow=c(1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feef9eaa",
      "metadata": {
        "id": "feef9eaa"
      },
      "source": [
        "If we fit the model\n",
        "$$\\mu(Y|X_1,X_2)=\\beta_0+\\beta_1X_1+\\beta_2X_2,$$\n",
        "we should observe that $X_1$ is significant, but $X_2$ is not. However, because of the correlation between $X_1$ and $X_2$ we obtain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa0c7a1",
      "metadata": {
        "id": "4aa0c7a1"
      },
      "outputs": [],
      "source": [
        "# Fit the model with multicollinearity\n",
        "mcol.yes <- lm(Y ~ X1 + X2)\n",
        "summary(mcol.yes)\n",
        "\n",
        "cloud(Y ~ X1 + X2,\n",
        "      scales =  list(arrows = FALSE),\n",
        "      pch=19,\n",
        "      xlim = c(0, 20), ylim = c(0, 20), zlim = c(0, 350),\n",
        "      main=\"Multicollinearity Yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae54a8e5",
      "metadata": {
        "id": "ae54a8e5"
      },
      "source": [
        "On the other hand, when we fit the model $$\\mu(Y|X_1,X_3)=\\beta_0+\\beta_1X_1+\\beta_3X_3,$$\n",
        "where there is no correlation bewteen $X_1,X_3$ we obtain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de8f10c",
      "metadata": {
        "id": "6de8f10c"
      },
      "outputs": [],
      "source": [
        "# Fit the model without multicollinearity\n",
        "mcol.no <- lm(Y~X1+X3)\n",
        "summary(mcol.no)\n",
        "\n",
        "cloud(Y ~ X1+ X3,\n",
        "      scales = list(arrows = FALSE),\n",
        "      pch=19,\n",
        "      xlim = c(0, 20), ylim = c(0, 20), zlim = c(0, 350),\n",
        "      main=\"Multicollinearity No\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f4e892",
      "metadata": {
        "id": "28f4e892"
      },
      "source": [
        "Note that multicollinearity is affecting the standard errors for the estimated coefficients for $X_1$ in each model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2413c0",
      "metadata": {
        "id": "bc2413c0"
      },
      "outputs": [],
      "source": [
        "# Look a standard errors in the model with multicollinearity\n",
        "summary(mcol.yes)$coef\n",
        "\n",
        "# Look a standard errors in the model without multicollinearity\n",
        "summary(mcol.no)$coef"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddf3a4e2",
      "metadata": {
        "id": "ddf3a4e2"
      },
      "source": [
        "If the standard errors are large, then the t-values are small. And if the t-values are small, the P-values are large, suggesting the corresponding variables are not significant.\n",
        "\n",
        "## 5.2 Why multicollinearity can be an issue?\n",
        "\n",
        "- The least squares estimates of the regression coefficients will have big standard errors.\n",
        "- The corresponding t-values will be small, and the P-values will be large (suggesting no significant effects even if there are).\n",
        "- Because of the loss of precision in estimation adding/deleting a few\n",
        "observations can have huge effects on the parameter estimates, making the interpretation difficult.\n",
        "\n",
        "Note that all these are problematic when your model objective is to identify \"relevant variables\".\n",
        "\n",
        "But, even under multicollinearity, your parameter estimates will still be unbiased and your model can offer a good fit.\n",
        "\n",
        "We can use graphical tools to assess the correlation between variables, like a matrix of scatterplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0bfc3d",
      "metadata": {
        "tags": [
          "remove_input"
        ],
        "id": "fd0bfc3d"
      },
      "outputs": [],
      "source": [
        "pairs(~ Y + X1 + X2 + X3, col = \"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07672bf3",
      "metadata": {
        "id": "07672bf3"
      },
      "source": [
        "# 6. Monte Carlo Simulations\n",
        "\n",
        "Let's finish with some Monte Carlo simulations to estimate the prediction uncertainty in the models we used in the previous example.\n",
        "\n",
        "Monte Carlo simulations typically consists of generating observations based on known distributions that we assume to be truth for our models.\n",
        "\n",
        "In the previous sections we considered two different models of the form\n",
        "$$\n",
        "\\mu\\{Y|X_1, X_2=\\beta_0+\\beta_1X_1+\\beta_2X_2\\quad \\text{(with multicol.)}\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\mu\\{Y|X_1, X_3=\\beta_0+\\beta_1X_1+\\beta_3X_3\\quad \\text{without multicol.}\n",
        "$$\n",
        "\n",
        "And Suppose we want to estimate the uncertainty in the prediction of the response $Y$ when $X_1=X_2=X_3=10$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700a3781",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "700a3781"
      },
      "outputs": [],
      "source": [
        "# Fix values of X1 - X3\n",
        "X1_new = 10\n",
        "X2_new = 10\n",
        "X3_new = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e611aadd",
      "metadata": {
        "id": "e611aadd"
      },
      "source": [
        "## 5.1 Multicollinearity model (wrong approach)\n",
        "Since the estimated coefficients have uncertainties (standard errors), a first approach could be to generate values for these coefficients using a known distribution and see how the error propagates throughout the model.\n",
        "\n",
        "We get beta coefficients and standard errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e860e09",
      "metadata": {
        "id": "0e860e09"
      },
      "outputs": [],
      "source": [
        "# beta coefficients\n",
        "B0 = mcol.yes$coefficients[\"(Intercept)\"]\n",
        "B1 = mcol.yes$coefficients[\"X1\"]\n",
        "B2 = mcol.yes$coefficients[\"X2\"]\n",
        "\n",
        "# beta standard errors\n",
        "std.errors = sqrt(diag(vcov(mcol.yes)))\n",
        "\n",
        "B0_se = std.errors[\"(Intercept)\"]\n",
        "B1_se = std.errors[\"X1\"]\n",
        "B2_se = std.errors[\"X2\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eae7a74",
      "metadata": {
        "id": "0eae7a74"
      },
      "source": [
        "Then simulate coefficients and response values \"independently\" according to a Normal distribution, based on the assumptions of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7eac1f0",
      "metadata": {
        "id": "a7eac1f0"
      },
      "outputs": [],
      "source": [
        "# Perform N.sims simulations\n",
        "N.sims = 1000\n",
        "\n",
        "# And generate the coefficients according to our previous model's estiamtes.\n",
        "B0_sims <- rnorm(N.sims, mean = B0, sd = B0_se)\n",
        "B1_sims <- rnorm(N.sims, mean = B1, sd = B1_se)\n",
        "B2_sims <- rnorm(N.sims, mean = B2, sd = B2_se)\n",
        "\n",
        "# For each simulated value we produce a predicted value for the response using\n",
        "# the model.\n",
        "y_sims = B0_sims + X1_new * B1_sims + X2_new * B2_sims"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7765affa",
      "metadata": {
        "id": "7765affa"
      },
      "source": [
        "Looking at the histogram of the simulated responses we obtain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b470e8a6",
      "metadata": {
        "id": "b470e8a6"
      },
      "outputs": [],
      "source": [
        "hist(y_sims, breaks = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ee3a0e",
      "metadata": {
        "id": "87ee3a0e"
      },
      "source": [
        "We can look at the 2.5th and 97.5th percentiles to obtain a prediction interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfd94e7",
      "metadata": {
        "id": "bdfd94e7"
      },
      "outputs": [],
      "source": [
        "# Prediction interval lower bound\n",
        "quantile(y_sims, p = c(0.025, 0.975))\n",
        "\n",
        "predict(mcol.yes,\n",
        "        newdata = list(X1 = X1_new, X2 = X2_new),\n",
        "        interval = \"confidence\",\n",
        "        level = 0.95)\n",
        "\n",
        "predict(mcol.yes,\n",
        "        newdata = list(X1 = X1_new, X2 = X2_new),\n",
        "        interval = \"prediction\",\n",
        "        level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cadf4e2",
      "metadata": {
        "id": "5cadf4e2"
      },
      "source": [
        "We observe that our prediction was far from what we get using the \"predict\" function. Could this be due to multicollinearity?\n",
        "\n",
        "## 5.2 No Multicollinearity model (wrong approach)\n",
        "We repeat the same exercise , but now using the model without multicollinearity.\n",
        "\n",
        "We get beta coefficients and standard errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1ee4aa",
      "metadata": {
        "id": "5f1ee4aa"
      },
      "outputs": [],
      "source": [
        "# beta coefficients\n",
        "B0 = mcol.no$coefficients[\"(Intercept)\"]\n",
        "B1 = mcol.no$coefficients[\"X1\"]\n",
        "B3 = mcol.no$coefficients[\"X3\"]\n",
        "\n",
        "# beta standard errors\n",
        "std.errors = sqrt(diag(vcov(mcol.no)))\n",
        "\n",
        "B0_se = std.errors[\"(Intercept)\"]\n",
        "B1_se = std.errors[\"X1\"]\n",
        "B3_se = std.errors[\"X3\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13368a4",
      "metadata": {
        "id": "c13368a4"
      },
      "source": [
        "Now we generate simulated values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4221f3c4",
      "metadata": {
        "id": "4221f3c4"
      },
      "outputs": [],
      "source": [
        "# Perform N.sims simulations\n",
        "N.sims = 1000\n",
        "\n",
        "# And generate the coefficients according to our previous model's estiamtes.\n",
        "B0_sims <- rnorm(N.sims, mean = B0, sd = B0_se)\n",
        "B1_sims <- rnorm(N.sims, mean = B1, sd = B1_se)\n",
        "B3_sims <- rnorm(N.sims, mean = B3, sd = B3_se)\n",
        "\n",
        "# For each simulated value we produce a predicted value for the response using\n",
        "# the model.\n",
        "y_sims = B0_sims + X1_new * B1_sims + X3_new * B3_sims"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b275a7",
      "metadata": {
        "id": "e1b275a7"
      },
      "source": [
        "Look at histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44df163c",
      "metadata": {
        "id": "44df163c"
      },
      "outputs": [],
      "source": [
        "hist(y_sims, breaks = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4247e92e",
      "metadata": {
        "id": "4247e92e"
      },
      "source": [
        "Still no good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4d64b5",
      "metadata": {
        "id": "9f4d64b5"
      },
      "outputs": [],
      "source": [
        "# Prediction interval using simulated response values\n",
        "quantile(y_sims, p = c(0.025, 0.975))\n",
        "\n",
        "# Using predict\n",
        "predict(mcol.no,\n",
        "        newdata = list(X1 = X1_new, X3 = X3_new),\n",
        "        interval = \"prediction\",\n",
        "        level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b255cc44",
      "metadata": {
        "id": "b255cc44"
      },
      "source": [
        "Comparing with the values produced with the \"predict\" function, we are still way off. So the issue is NOT due to multicollinearity.\n",
        "\n",
        "## The proper simulation approach\n",
        "\n",
        "The problem is that in the previous approach we did not take into account the correlation structure between the estimated coefficients. To do so, we will need to use the package \"MVNorm\", which we loaded at the top of this notebook document.\n",
        "\n",
        "Now, we repeat our previous exercise with the \"No Multicollinearity\" model first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e11beac",
      "metadata": {
        "id": "8e11beac"
      },
      "outputs": [],
      "source": [
        "N.sims = 1000\n",
        "coef_samples = rmvnorm(N.sims,\n",
        "                       mean = coef(mcol.no),\n",
        "                       sigma = vcov(mcol.no))\n",
        "\n",
        "y_without <- coef_samples %*% matrix(c(1, 10, 10), ncol = 1)\n",
        "yp_without = y_without + rnorm(N.sims, sd = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0894088",
      "metadata": {
        "id": "c0894088"
      },
      "source": [
        "And we look at the interval based on the quantiles of the simulated values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2401dc7",
      "metadata": {
        "id": "a2401dc7"
      },
      "outputs": [],
      "source": [
        "# CI\n",
        "quantile(y_without, p = c(0.025, 0.975))\n",
        "predict(mcol.no,\n",
        "        newdata = list(X1 = 10, X3 = 10),\n",
        "        interval = \"confidence\",\n",
        "        level = 0.95)\n",
        "\n",
        "# PI\n",
        "quantile(yp_without, p = c(0.025, 0.975))\n",
        "predict(mcol.no,\n",
        "        newdata = list(X1 = 10, X3 = 10),\n",
        "        interval = \"prediction\",\n",
        "        level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4f635f",
      "metadata": {
        "id": "fa4f635f"
      },
      "source": [
        "Observe there is a difference now between the confidence intervals and prediction intervals we obtain with the prediction. Can you see where is that difference in the code?\n",
        "\n",
        "Repeating the exercise for the model \"With Multicollinearity\", we obtain now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ca55fb",
      "metadata": {
        "id": "69ca55fb"
      },
      "outputs": [],
      "source": [
        "coef_samples = rmvnorm(N.sims,\n",
        "                       mean = coef(mcol.yes),\n",
        "                       sigma = vcov(mcol.yes))\n",
        "\n",
        "y_with = coef_samples %*% matrix(c(1, 10, 10), ncol = 1)\n",
        "yp_with = y_with + rnorm(N.sims, sd = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe7251d",
      "metadata": {
        "id": "ebe7251d"
      },
      "outputs": [],
      "source": [
        "# CI\n",
        "quantile(y_with, p = c(0.025, 0.975))\n",
        "predict(mcol.yes,\n",
        "        newdata = list(X1 = 10, X2 = 10),\n",
        "        interval = \"confidence\",\n",
        "        level = 0.95)\n",
        "\n",
        "# PI\n",
        "quantile(yp_with, p = c(0.025, 0.975))\n",
        "predict(mcol.yes,\n",
        "        newdata = list(X1 = 10, X2 = 10),\n",
        "        interval = \"prediction\",\n",
        "        level = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d2ae1b2",
      "metadata": {
        "id": "8d2ae1b2"
      },
      "source": [
        "We observe that we can obtain good results, but we need to be very careful in the way we implement the Monte Carlo simulation."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "echo,tags,name,-all",
      "main_language": "R",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "R"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}